---
title: "Exercise_05_Challenge_1"
author: "SLCornett"
date: "2/21/2022"
output: html_document
editor_options: 
  chunk_output_type: inline
---

```{r}
library(tidyverse)
library(mosaic)
library(dplyr)
library(ggplot2)
```
1. Using the {tidyverse} read_csv() function, load the “IMDB-movies.csv” dataset from this URL as a “tibble” named d
```{r}
f1 <- "https://raw.githubusercontent.com/difiore/ada-2022-datasets/main/IMDB-movies.csv"
d <- read_csv(f1, col_names = TRUE)
df<- d %>% filter(startYear %in% 1920:1979, runtimeMinutes %in% 60:180) %>%
  mutate("decade"=case_when(startYear %in% 1920:1929~"20s",
                            startYear %in% 1930:1939~"30s",
                            startYear %in% 1940:1949~"40s",
                            startYear %in% 1950:1959~"50s",
                            startYear %in% 1960:1969~"60s",
                            startYear %in% 1970:1979~"70s"
                            )
         )
print(df)
```
A: Table has 5,651 items
.
2. Use {ggplot2} (which is part of {tidyverse}) to plot histograms of the distribution of runtimeMinutes for each decade
```{r}
# boxplot(runtimeMinutes ~ startYear, data=df, xlab="Decade", ylab="runtime (min)") #test that decade works in general, it does
p <- ggplot(data = df)  #object built (in theory) -> don't need aes(x, y) here because R gets confused and angry
p <- p + xlab("Runtime (min)") + ylab("Density") #data labels
#p <- p + geom_point(na.rm=TRUE) # makes a "scatterplot" that's more a bar graph of dots
#p <- p + histogram(~ decades, data = df$runtimeMinutes, xlab = "Runtime (min)") #incompatible and also just doesn't work with ggplot2, or on its own
p<- p + geom_histogram(aes(x=runtimeMinutes,#no need y= or stat=identity
                                    color=factor(decade),
                                    binwidth = 30,
                                    )) #x, y, alpha, color, fill, linetype, size, weight
p

p <- p + facet_wrap(~ decade, ncol=4) # wrap data "by" decade into 4 columns
p
```

3. Use a one-line statement to calculate the population mean and population standard deviation in *runtimeMinutes* for each decade and save the results in a new dataframe called "results".
```{r}
#actual population
results <- group_by(df, decade)%>%
  summarise(
    p_mean=mean(runtimeMinutes, na.rn=TRUE), #population mean
    p_sd=sd(runtimeMinutes, na.rm=TRUE), #population sd
    p_se=p_sd/sqrt(100) #se
    )
print(results) # population mean, standard deviation, standard error
```

4-5. [A] Draw a single sample of 100 movies, without replacement, from each decade and calculate the single sample mean and single sample standard deviation in *runtimeMinutes* for each *decade*. Recall that your single sample mean for each decade is an estimate of the population mean for each decade. [B] Calculate for each decade the standard error around your estimate of the population mean runtimeMinutes based on the standard deviation and sample size (n=100 movies) of your single sample.
```{r}
x <- group_by(df, decade) %>%
  sample_n(100, replace = FALSE) %>% #no replacement
  summarise(
    samp_mean=mean(runtimeMinutes, na.rn=TRUE), #sample mean
    samp_sd=sd(runtimeMinutes, na.rm=TRUE), #sample sd
    samp_se=samp_sd/sqrt(100) #sample standard error
    ) # pull single sample from 100 movies for each decade
x #prints the results
```
6. Compare these estimates to the actual population mean *runtimeMinutes* for each decade and to the calculated SE in the population mean for samples of size 100 based on the population standard deviation for each decade.
```{r}
#actual population = results
#SE calculation pop of sample of 100 = x
comparison <- left_join(x, results, by = "decade") #merge also works (module 10)
print(comparison) #prints the left-joined tables of x and results

#also works: Merge {dyplyr}
#comparison_1 <- merge(x, results, by = "decade")
#print(comparison_x_results)
```

7. Generate a sampling distribution of mean *runtimeMinutes* for each decade by 
[a] drawing 1000 samples of 100 movies from each decade and, for each sample, 
[b] calculating the mean *runtimeMinutes* and the standard deviation in *runtimeMinutes* for each decade. 
-> Use either the do(reps) * formulation from {mosaic}, the rerun() function from {purrr}, or the rep_sample_n() workflow from {infer} to generate your these sampling distributions (see Module 12)
```{r}
#runtimeMinutes sampling distribution (samp_dist = s from assignment)
reps<- 1000
n <- 100
samp_dist<-do(reps) * sample_n(group_by(df, decade), n, replace=FALSE) %>% #group by decade to sample
  group_by(decade) %>%  # group by sample in results
  summarise(samp_dist_mean=mean(runtimeMinutes, na.rm=TRUE), #sampling distrib mean
            samp_dist_sd=sd(runtimeMinutes, na.rm=TRUE)) #sampling distrib sd
samp_dist #print s
```

8. [A] calculate the *MEAN* and the *STANDARD DEVIATION* of the Sampling Distribution of sample means for each decade (the former should be a very good estimate of the population mean, while the latter is another estimate of the standard error in our estimate of the population mean for a particular sample size) and [B] plot a histogram of the sampling distribution for each decade. What shape does it have?
```{r}
#A
mean(~ samp_dist_mean, data=samp_dist) #calculates the mean for 

#B
ggplot(data = samp_dist, aes(x=samp_dist_mean)) + geom_histogram() + facet_wrap(~decade)
```
A: normal distribution, shaped like the empire state building. 


9. Finally, compare the standard error in *runtimeMinutes* for samples of size 100 from each decade 
[1] as estimated from your first sample of 100 movies, 
[2] as calculated from the known population standard deviations for each decade, and 
[3] as estimated from the sampling distribution of sample means for each decade.
```{r}

```


